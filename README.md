
# ğŸ§  LLM Training Journey (julâ€“dic 2025)

Este repositorio documenta mi camino para aprender a crear, entrenar y desplegar un modelo de lenguaje grande (LLM) desde cero antes de diciembre de 2025. A continuaciÃ³n, encontrarÃ¡s el cronograma detallado por semanas, incluyendo teorÃ­a, prÃ¡ctica, recursos y entregables.

---

## ğŸ”¹ Semana 0 (8â€“14 jul): OrientaciÃ³n & base moderna de Transformers
**Recursos**:
- [Hugging Face LLM Course â€“ Track Scientist](https://huggingface.co/blog/mlabonne/llm-course)
- [Attention Is All You Need (paper)](https://arxiv.org/abs/1706.03762)

**Actividades**:
- Repaso opcional: Python avanzado, PyTorch.
- Completar lecciones 1â€“3 del LLM Course.
- Implementar un encoder Transformer bÃ¡sico.

**Entregable**: Notebook con self-attention + curvas de pÃ©rdida.

---

## ğŸ”¹ Semana 1 (15â€“21 jul): nanoGPT & Scaling Laws
**Recursos**:
- [Letâ€™s Build GPT â€“ Andrej Karpathy (video)](https://youtu.be/kCc8FmEb1nY)
- [nanoGPT (repo)](https://github.com/karpathy/nanoGPT)
- [Scaling Laws for LMs (paper)](https://arxiv.org/abs/2001.08361)

**Actividades**:
- Clonar nanoGPT, explorar el cÃ³digo.
- Entrenar modelo de 6M parÃ¡metros.
- Resumir 3 hallazgos de escalamiento.

**Entregable**: Script + informe de resultados.

---

## ğŸ”¹ Semana 2 (22â€“28 jul): ConstrucciÃ³n de corpus limpio
**Recursos**:
- [trafilatura (scraping)](https://github.com/adbar/trafilatura)
- [datasketch (MinHash)](https://ekzhu.github.io/datasketch/)
- [fastText (lang-id)](https://fasttext.cc/)

**Actividades**:
- Scraping y limpieza de texto gubernamental.
- Filtrado de idioma y deduplicaciÃ³n.
- Guardado final en Parquet.

**Entregable**: Corpus limpio con mÃ©tricas.

---

## ğŸ”¹ Semana 3 (29 jul â€“ 4 ago): TokenizaciÃ³n personalizada
**Recursos**:
- [HF Tokenizers Course](https://huggingface.co/learn/nlp-course/chapter6/6)
- [tokenizers API](https://github.com/huggingface/tokenizers)

**Actividades**:
- Entrenar tokenizer BPE (50k).
- Medir coverage y publicar en HF Hub.

**Entregable**: Tokenizer entrenado + anÃ¡lisis.

---

## ğŸ”¹ Semana 4 (5â€“11 ago): Arquitectura GPT (â€œMiniGPTâ€)
**Recursos**:
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [FlashAttention-3](https://github.com/Dao-AILab/flash-attention)

**Actividades**:
- Codificar bloques GPT en PyTorch.
- Integrar FlashAttention.
- Validar con pruebas unitarias.

**Entregable**: MÃ³dulo MiniGPT documentado.

---

## ğŸ”¹ Semana 5 (12â€“18 ago): Entrenamiento inicial (125M)
**Recursos**:
- [HF Efficient Transformers](https://huggingface.co/blog/efficient-transformers)
- [Weights & Biases](https://wandb.ai/)

**Actividades**:
- Configurar entrenamiento con FlashAttention y Lightning.
- Monitorear entrenamiento.

**Entregable**: Modelo 125M entrenado + dashboard de mÃ©tricas.

---

## ğŸ”¹ Semana 6â€“7 (19 ago â€“ 1 sep): Modelo 350â€“700M con FSDP
**Recursos**:
- [FSDP Tutorial PyTorch](https://docs.pytorch.org/tutorials/intermediate/FSDP_tutorial.html)

**Actividades**:
- Implementar y probar FSDP.
- Entrenar modelo completo 350M.

**Entregable**: Modelo entrenado + curvas.

---

## ğŸ”¹ Semana 8â€“9 (2â€“15 sep): Fine-tuning PEFT (LoRA)
**Recursos**:
- [PEFT Docs â€“ HF](https://huggingface.co/docs/peft/index)

**Actividades**:
- Preparar dataset conversacional.
- Afinar con LoRA.

**Entregable**: Modelo LoRA afinado + mÃ©tricas.

---

## ğŸ”¹ Semana 10 (16â€“22 sep): AlineaciÃ³n con DPO
**Recursos**:
- [DPO paper](https://arxiv.org/abs/2305.18290)
- [TRL library](https://github.com/huggingface/trl)

**Actividades**:
- Extraer pares de preferencias.
- Aplicar DPO.

**Entregable**: Modelo alineado + comparaciÃ³n.

---

## ğŸ”¹ Semana 11â€“12 (23 sep â€“ 6 oct): QuantizaciÃ³n y Serving
**Recursos**:
- [llama.cpp (GGUF)](https://github.com/ggerganov/llama.cpp)
- [vLLM](https://vllm.ai)

**Actividades**:
- Cuantizar modelo y evaluar pÃ©rdida.
- Servir en vLLM con latencia <200 ms.

**Entregable**: Modelo listo para producciÃ³n.

---

## ğŸ”¹ Semana 13â€“15 (7â€“27 oct): Escalado en la nube (1â€“3B)
**Recursos**:
- [DeepSpeed ZeRO-3](https://deepspeed.ai/tutorials/zero/)

**Actividades**:
- Configurar entorno A100 (LambdaLabs).
- Entrenar modelo 1.3B completo.

**Entregable**: Checkpoint + logs + evaluaciÃ³n.

---

## ğŸ”¹ Semana 16â€“17 (28 oct â€“ 10 nov): Federated (opcional)
**Recursos**:
- [Flower](https://flower.ai)
- [Photon](https://github.com/epfml/photon)

**Actividades**:
- Prueba de entrenamiento federado.

**Entregable**: Miniinforme tÃ©cnico.

---

## ğŸ”¹ Semana 18â€“19 (11â€“24 nov): EvaluaciÃ³n
**Recursos**:
- [RAGAS](https://github.com/explodinggradients/ragas)
- [HELM](https://crfm.stanford.edu/helm/latest/)

**Actividades**:
- Evaluar con RAGAS y HELM.

**Entregable**: Comparativa de desempeÃ±o vs GPTs.

---

## ğŸ”¹ Semana 20â€“22 (25 nov â€“ 15 dic): IntegraciÃ³n
**Actividades**:
- Integrar modelo en microservicio `ms-chats`.
- Simular uso concurrente y analizar.

**Entregable**: Demo funcional en entorno real.

---

## ğŸ”¹ Semana 23â€“25 (16â€“29 dic): DocumentaciÃ³n y entrega final
**Actividades**:
- Escribir white-paper.
- Grabar video demo.
- Preparar presentaciÃ³n final.

**Entregable**: Paquete de entrega final documentado.

---

## âœ… Repaso opcional (no se elimina, se refuerza si es necesario)
- Python avanzado, PEP-8, PyTorch
- Docker, Git, entornos venv
- VisiÃ³n computacional (YOLO, OCR)
- LangChain, LangGraph, RAG y SQL (tus agentes)

---

Este plan es intensivo (6â€“7 h diarias), progresivo y estÃ¡ diseÃ±ado para que puedas crear y entrenar un LLM desde cero en un entorno real.

Â¡Vamos con todo!
